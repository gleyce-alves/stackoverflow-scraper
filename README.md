# Stack Overflow Scraper - Public API-Based Scraping Mechanism

This project consists of four Python scripts that demonstrate an automated scraping mechanism for Stack Overflow, utilizing the platform's public API. The scripts perform the following tasks:

## Main Script (`main.py`)

- This is the entry point of the project. To execute, simply run `python3 main.py`.
- Its main function is to coordinate the execution flow of the other scripts.
- It calls **Script A** (`execute_and_capture_error.py`) to initiate the process.

## Script A (`execute_and_capture_error.py`)

- **Script A** is responsible for running **Script B** and capturing the error message generated by it.
- First, it executes **Script B** (`error.py`) to simulate a specific error. In the provided example, the error is a division by zero.
- Next, it captures the error message generated by **Script B**.
- After capturing the error message, it displays it in the console.
- Finally, **Script A** calls **Script C** (`search_stackoverflow.py`) to search for solutions to the captured error on Stack Overflow (https://stackoverflow.com/) via its public API (https://api.stackexchange.com/).

## Script B (`error.py`)

- **Script B** is a simple script containing code that intentionally generates an error. In the given example, it generates a division by zero error, but it can be customized to generate other common error types. Currently, this error is manually generated, but future improvements could automate this process.

## Script C (`search_stackoverflow.py`)

- **Script C** is responsible for performing a search on Stack Overflow to find solutions related to the captured error message.
- It uses Stack Overflow's public API (https://api.stackexchange.com/) to conduct this search.
- After obtaining search results, it extracts the first solution and displays it in the console.

## Requirements

Ensure you have Python 3.10.x installed on your system. You will also need to install the dependencies listed in the `requirements.txt` file.

## How to Use

Follow these steps to run the scraping mechanism:

1. Clone the repository to your local machine:

	```bash
	git clone https://github.com/gleyce-alves/stackoverflow-scraper.git
	```
2. Navigate to the project directory:

	```bash
	cd stackoverflow-scraper
	```
3. Make sure you have a virtual environment (virtualenv) activated where project dependencies are installed from the `requirements.txt` file. Otherwise, you can create and activate a virtual environment:

	3.1 For Linux/macOS:
	
	```bash
	python3 -m venv env
	source env/bin/activate
	```

	3.2 For Windows:

	```bash
	python -m venv env
	.\env\Scripts\activate
	```
4. Install the project dependencies using `pip`:

	```bash
	pip install -r requirements.txt
	```

5. To run the project, execute the `main.py` file::

	```bash
	python main.py
	```

## Example

Suppose you want to understand how the scraping mechanism works. Here is an example output:

```python
The encountered error was:
Traceback (most recent call last):
  File "/path/to/error.py", line 1, in <module>
    result = 10 / 0
ZeroDivisionError: division by zero

Captured error message:
ZeroDivisionError: division by zero

```
In this example, **Script A** executed **Script B**, which generated a division by zero error. Then, Script A captured and displayed the error message. Subsequently, **Script C** searched Stack Overflow for solutions related to the error message.

This project offers an automated and efficient way to search for answers on Stack Overflow, saving time when solving common programming problems.

## Ideas for Continuous Improvement

- Implement advanced search options, such as filtering by programming language.
- Add support for searching multiple error messages in a single execution.
- Enhance the output formatting to make solutions more readable.

